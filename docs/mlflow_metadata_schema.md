# MLflow metadata schema (select → infer)

This document defines how we name and store metadata for model selection and inference using MLflow.

## Goals
- Make runs easy to compare and filter (by dataset/timeframe/target/metric).
- Make inference safe and reproducible (stage/alias + exact config + model path).
- Keep UI clean: predictable names, minimal tags, structured params/metrics, curated artifacts.

## High level categories
- **Experiment** (group comparable runs, defined by user)
  - Purpose: group multiple runs with simliar inputs and same target, so we can compare the performance and register best models
  - Name: decided by user, should be descriptive and very human readable.

- **Run** (identifier of model training run)
  - Purpose: mark each model training run
  - Name: generated by model training script
    - LGBM: `run_YYYYMMDD_HHMMSS_lgbm_{target}_{objective}` (e.g., `run_20251008_145809_lgbm_y_logret_168h_huber`)
    - HMM: `run_hmm_YYYYMMDD_HHMMSS`

- **Model Registry** (for model selection and inference)
  - **Model name:** decided by user for their inference pipeline.
  - **Version description:** human summary of the model.
  - **Aliases:** `Staging` or `Production` (visible on Model → Versions).

## For each **Run**

### Params (structured; for search/filter)
Record these under MLflow “params”, sourced from the run’s config/artifacts:
- `model_type`: e.g., `lgbm` | `hmm`
- `target`: supervised variable (e.g., `y_logret_168h`); for unsupervised/HMM use `unsupervised target`
- `objective`: e.g., `huber` | `binary` | `tweedie` (may be omitted for HMM)
- `primary_metric`: LGBM defaults by objective (`rmse` | `auc` | `pinball_loss`); HMM uses selection criterion (`bic` | `icl`)
- `dataset_slug`: sanitized dataset id (replace spaces/commas with `_`), e.g., `BINANCE_BTCUSDT.P__60`
- `prepared_data_dir`: path to prepared data directory (if produced)
- `output_dir`: runs root
- `input_data`: absolute path when training from a single CSV (no feature store)
- `feature_store.features_csv`, `feature_store.targets_csv`: absolute paths when using a feature store
- `extra_feature_files.{i}.path`, `extra_feature_files.{i}.include`: extra feature inputs (flattened)
- `feature_list_id`: feature list identifier; use `NA` if not present
- `hyperparam_tuning`: `1` if tuning configured (e.g., LGBM `hyperparameter_tuning_method` or HMM `state_grid` present), else `0`
- `run_dir`, `model_path`: absolute paths for auditability
- `external_model_path`: model file path when not copied into MLflow artifacts

### Metrics (numeric; for comparison)
Record these under MLflow “metrics” (may add more):
- LGBM regression: `rmse_train`, `rmse_val`, `rmse_test` and `corr_train`, `corr_val`, `corr_test`
- LGBM classification: `auc_train`, `auc_val`, `auc_test` and `logloss_train`, `logloss_val`, `logloss_test`
- HMM: `n_states`, `bic_final`, `aic_final`, `icl_final`, `entropy_final`, `train_final_ll`, `test_ll`, `rows`, `n_features`

### Tags (human-curated; minimal)
- Reserve tags for human edits only (e.g., notes, ad-hoc labels). Do not duplicate structured params here.

### Artifacts (files from run directory)
- Default: log all files under the run directory.
- LGBM typical: `model.txt`, `metrics.json`, `pred_train/val/test.csv`, `feature_importance.csv`, `run_metadata.json`, `pipeline_config.json`, `best_params.json`, `paths.json`, `prep_metadata.json` (if copied)
- HMM typical: `model.joblib`, `scaler.joblib`, `regimes.csv`, `selection_grid.csv`, `prep_metadata.json`, `diagnostics.json`, `metrics.json`, `pipeline_config.json`
- Path hygiene: prefer sanitized directories (no spaces/commas) or use a sanitized symlink when logging artifacts

## Examples

### LGBM regression
- Experiment: `binance-btcusdt-perp-1h-7d-logret`
- Run: `run_20251008_145809_lgbm_y_logret_168h_huber`
- Params (subset): `{model_type: lgbm, target: y_logret_168h, objective: huber, primary_metric: rmse, dataset_slug: BINANCE_BTCUSDT.P__60, prepared_data_dir: /.../prepared_..., output_dir: /.../models/BINANCE_BTCUSDT.P, 60, feature_store.features_csv: /.../features.csv, feature_store.targets_csv: /.../targets.csv, feature_list_id: binance_btcusdt_p60_default, hyperparam_tuning: 1, run_dir: /.../run_20251008_145809_lgbm_y_logret_168h_huber, model_path: /.../model.txt}`
- Metrics (subset): `{rmse_train: 0.0548, rmse_val: 0.0669, rmse_test: 0.0448, corr_val: 0.315}`
- Artifacts: all files under the run directory
- Registry: Model `btcusdt-1h-inference-7d-logret` → Aliases `Staging`

### HMM (unsupervised)
- Experiment: `hmm-btcusdt-1h`
- Run: `run_hmm_20251009_105640`
- Params (subset): `{model_type: hmm, target: "unsupervised target", primary_metric: bic, dataset_slug: BINANCE_BTCUSDT.P__60, output_dir: /.../models/BINANCE_BTCUSDT.P, 60, input_data: /.../features.csv, feature_list_id: NA, hyperparam_tuning: 1, run_dir: /.../run_hmm_20251009_105640, model_path: /.../model.joblib}`
- Metrics (subset): `{n_states: 15, bic_final: 212234.27, icl_final: 212145.16, train_final_ll: -103687.26, test_ll: -18482.57}`
- Artifacts: `model.joblib`, `scaler.joblib`, `regimes.csv`, `selection_grid.csv`, `prep_metadata.json`, `diagnostics.json`, `metrics.json`, `pipeline_config.json`

### Notes
- Prefer params for structured fields from model training config or run metadata; reserve tags for human edits.
- Avoid spaces/commas in artifact root paths (use sanitized directories or symlinks).
